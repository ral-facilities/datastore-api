[![Build Status](https://github.com/ral-facilities/datastore-api/workflows/CI/badge.svg?branch=main)](https://github.com/ral-facilities/datastore-api/actions?query=workflow%3A%22CI%22)
[![Codecov](https://codecov.io/gh/ral-facilities/datastore-api/branch/main/graph/badge.svg)](https://codecov.io/gh/ral-facilities/datastore-api)

# Datastore-API

The Datastore API accepts requests for the archival or retrieval of experimental data.
These trigger subsequent requests to create corresponding metadata in [ICAT](https://icatproject.org/), and schedules the transfer of the data using [FTS3](https://fts3-docs.web.cern.ch/fts3-docs/).

## Deployment
To run the API (while sourcing the virtual environment):

```bash
uvicorn --host=127.0.0.1 --port=8000 --log-config=logging.ini --reload datastore_api.main:app
```

To run from outside of the virtual environment, add `poetry run` to the beginning of the above command.
Changing the optional arguments as needed. Documentation can be found by navigating to `/docs`.

## Development

### Environment setup
To develop the API Python development tools will need to be installed. The exact command will vary, for example on Rocky 8:

```bash
sudo yum install "@Development Tools" python3.11-devel python3.11 python3.11-setuptools openldap-devel swig gcc openssl-devel xrootd-client
```

Before running the API, create the `config.yaml` and `logging.ini` config files. A sample configuration can be copied from the `config.yaml.example` and `logging.ini.example` files.

In order to run against an external S3 storage instance (as opposed to using a Dockerised [MinIO](https://min.io/)), you will also need to generate and set access and secret keys. This can be achieved using the [STFC Cloud](https://openstack.stfc.ac.uk) in combination with [Echo](https://s3.echo.stfc.ac.uk):
1. [Generate credentials for the OpenStack CLI](https://stfc.atlassian.net/wiki/spaces/CLOUDKB/pages/1738070/Using+the+OpenStack+Command+Line+Interface)
2. [Generate credentials for Echo](https://stfc.atlassian.net/wiki/spaces/CLOUDKB/pages/377421872/S3+On+OpenStack)
3. Set the access and secret keys in a valid settings location along with the url for the S3 storage (such as `config.yaml`).

In order to authenticate against the FTS storage endpoints, you will need an X509 certificate. This can be [generated by request](https://portal.ca.grid-support.ac.uk/pub/requestUserCert/submitNewUserCertRequest), and then set in the location expected by the API's default settings (`hostcert.pem` and `hostkey.pem`).

Note that in order to run the full suite of tests, these settings will need to be present. The S3 keys are not specified in `pytest.ini`, and so Pydantic will attempt to load them from another location such as the `config.yaml`. If they are not set anywhere then validation will fail, and only tests which mock outgoing requests will be possible.

### Poetry
[Poetry](https://python-poetry.org/) is used to manage the dependencies of this API. Note that to prevent conflicts Poetry should not be installed in the environment used for the project dependencies; [different recommended installation methods are possible](https://python-poetry.org/docs/#installing-with-the-official-installer). _(Note that pipx may not install the latest version)_

The official documentation should be referred to for the management of dependencies, but to create a Python development environment:

```bash
poetry install
```

### Nox
[Nox](https://nox.thea.codes) is used to run tests and other tools in reproducible environments. As with poetry, this is not a direct dependency of the project and so should be installed outside the poetry managed virtual environment. Nox can run sessions for the following tools:
- `black` - this uses [Black](https://black.readthedocs.io/en/stable/) to format Python code to a pre-defined style.
- `lint` - this uses [flake8](https://flake8.pycqa.org/en/latest/) with a number of additional plugins (see the included `noxfile.py` to see which plugins are used) to lint the code to keep it Pythonic. `.flake8` configures `flake8` and the plugins.
- `safety` - this uses [safety](https://github.com/pyupio/safety) to check the dependencies (pulled directly from Poetry) for any known vulnerabilities. This session gives the output in a full ASCII style report.
- `tests` - this uses [pytest](https://docs.pytest.org/en/stable/) to execute the automated tests in `tests/`. Note that this will require a running ICAT (see below).
    - `unit_tests` - as above but only runs tests in `tests/unit`, which mock dependencies on other classes and external packages.
    - `integration_tests` - as above but only runs tests in `tests/integration`, which will not mock and therefore requires services such as ICAT and FTS to be running.

By executing 
```bash
nox -s [SESSIONS ...]
```

### Docker
A full ICAT installation with Payara can be used by following the standard [installation tutorial](https://github.com/icatproject/icat.manual/tree/master/tutorials).
Alternatively, [Docker](https://www.docker.com/) can be used to create and manage isolated environments for the services needed to test the API. 

To install Docker for the RHEL operating system from the rpm repository, run:

```bash
sudo yum install -y yum-utils
sudo yum-config-manager --add-repo https://download.docker.com/linux/rhel/docker-ce.repo
```

This will setup the repository and install the `yum-utils` package.
To install the latest version of Docker, run:

```bash
sudo yum install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin
```

_(Other installation methods can be found in the official [documentation](https://docs.docker.com/engine/install/rhel/#install-using-the-repository))._

To run Docker, `cd` to the _tests_ directory containing the compose file and run:

```bash
sudo docker compose up
```

To include optional components in the stack (such as MinIO, as an alternative to Echo) use the appropriate profile such as:

```bash
sudo docker compose --profile=minio up
```

### ICAT Setup
Following the above commands will create containers for ICAT and the underlying database, but not any data. The requests to the API implicitly assume that certain high level entities exist, so these should be created:

```bash
icatingest.py -i datastore_api/scripts/example.yaml -f YAML --duplicate IGNORE --url http://localhost:18080 --no-check-certificate --auth simple --user root --pass pw
```

If desired the entities in `example.yaml` can be modified or extended following the [python-icat documentation](https://python-icat.readthedocs.io/en/1.3.0/icatingest.html). There are other files which will create multiple entities, if needed.

To verify that the entities are created correctly, the usual methods of inspecting the database (either by the command line within its container or via DB inspection software) or running commands against ICAT (via curl or a full stack including frontend) are possible, however for these use cases the [ICAT admin](https://vigorous-lamarr-7b3487.netlify.app/) web app offers a simple and quick method of verifying the entities are created. The full address and port (e.g. http://localhost:18080 if using Docker to forward the container port to the host machine as described above) is needed along with the credentials used in the tests:
```yaml
auth: simple
username: root
password: pw
```
